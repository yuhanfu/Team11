{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv files to data frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv',encoding = \"latin1\")\n",
    "test_df = pd.read_csv('data/test.csv',encoding = \"latin1\")\n",
    "attributes_df = pd.read_csv('data/attributes.csv',encoding = \"latin1\")\n",
    "product_descriptions_df = pd.read_csv('data/product_descriptions.csv',encoding = \"latin1\")\n",
    "sample_submission_df = pd.read_csv('data/sample_submission.csv', encoding = \"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 int64\n",
      "product_uid        int64\n",
      "product_title     object\n",
      "search_term       object\n",
      "relevance        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_uid             int64\n",
      "product_description    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(product_descriptions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_uid             int64\n",
      "product_description    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(product_descriptions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_uid                                product_description\n",
      "0       100001  Not only do angles make joints stronger, they ...\n",
      "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
      "2       100003  Classic architecture meets contemporary design...\n",
      "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
      "4       100005  Update your bathroom with the Delta Vero Singl...\n"
     ]
    }
   ],
   "source": [
    "print(product_descriptions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NLTK's stopwords list and WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and tokenize the raw text by:\n",
    "    1. Convert to lower case\n",
    "    2. Remove apostrophe\n",
    "    3. Remove Punctuation\n",
    "    4. Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "   \n",
    "    # convert text to lower case\n",
    "    lowercase = str(text).lower()\n",
    "    \n",
    "    #remove 's from string\n",
    "    apoRemoved = lowercase.replace(\"'s\",\"\")\n",
    "    \n",
    "    #convert don't to dont\n",
    "    apoRemoved = apoRemoved.replace(\"'\",\"\")\n",
    "    \n",
    "    #handle other punctuations\n",
    "    transtable = str.maketrans(string.punctuation,\"                                \")\n",
    "    brokenWords = apoRemoved.translate(transtable)\n",
    "    \n",
    "    #convert string to list of words\n",
    "    listOfWords =  nltk.word_tokenize(brokenWords)\n",
    "    \n",
    "    #lemmatize text\n",
    "    lemmatizedList=[lemmatizer.lemmatize(word) for word in listOfWords]\n",
    "   \n",
    "    return lemmatizedList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'here', 'dont', 'car']\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "text = \"Dogs Here's don't cars.\"\n",
    "print(process(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process train_df\n",
    "def process_train_df(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \n",
    "    newdf=df\n",
    "    for i,row in newdf.iterrows():\n",
    "#         if i>5:\n",
    "#             break\n",
    "#         print(\"raw: \",text)\n",
    "        newdf.at[i,'product_title'] = process(row['product_title'])\n",
    "#         print(\"processed: \",df.iloc[i]['product_title'])\n",
    "    return newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid                                      product_title  \\\n",
      "0   2       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "1   3       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "2   9       100002  [behr, premium, textured, deckover, 1, gal, sc...   \n",
      "3  16       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "4  17       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "\n",
      "          search_term  relevance  \n",
      "0       angle bracket       3.00  \n",
      "1           l bracket       2.50  \n",
      "2           deck over       3.00  \n",
      "3    rain shower head       2.33  \n",
      "4  shower only faucet       2.67  \n"
     ]
    }
   ],
   "source": [
    "processed_train_df = process_train_df(train_df)\n",
    "lentr = len(processed_train_df['product_uid'])\n",
    "print(processed_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n"
     ]
    }
   ],
   "source": [
    "print(lentr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process \n",
    "def process_product_descriptions_df(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \n",
    "    newdf=df\n",
    "    for i,row in newdf.iterrows():\n",
    "#         if i>5:\n",
    "#             break\n",
    "#         print(\"raw: \",text)\n",
    "        newdf.at[i,'product_description'] = process(row['product_description'])\n",
    "#         print(\"processed: \",df.iloc[i]['product_title'])\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_uid                                product_description\n",
      "0       100001  [not, only, do, angle, make, joint, stronger, ...\n",
      "1       100002  [behr, premium, textured, deckover, is, an, in...\n",
      "2       100003  [classic, architecture, meet, contemporary, de...\n",
      "3       100004  [the, grape, solar, 265, watt, polycrystalline...\n",
      "4       100005  [update, your, bathroom, with, the, delta, ver...\n"
     ]
    }
   ],
   "source": [
    "processed_product_descriptions_df = process_product_descriptions_df(product_descriptions_df)\n",
    "print(processed_product_descriptions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [not, only, do, angle, make, joint, stronger, ...\n",
      "1    [behr, premium, textured, deckover, is, an, in...\n",
      "2    [classic, architecture, meet, contemporary, de...\n",
      "3    [the, grape, solar, 265, watt, polycrystalline...\n",
      "4    [update, your, bathroom, with, the, delta, ver...\n",
      "Name: product_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed_product_descriptions_df[\"product_description\"].head(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-7d30f4c50fe8>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-7d30f4c50fe8>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    query=rr[]\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# print(processed_product_descriptions_df[\"product_description\"].head(5) )\n",
    "# from nltk.corpus import wordnet\n",
    "# import numpy as np\n",
    "# query = 'shower head'\n",
    "# qa= query.split(\" \")\n",
    "# c=0\n",
    "# w1 = wordnet.synsets(\"dog\")[0]\n",
    "# w2 = wordnet.synsets(\"animal\")[0]\n",
    "# print(w1.wup_similarity(w2))\n",
    "# sLength = len(processed_product_descriptions_df[\"product_description\"])\n",
    "# print(sLength)\n",
    "# e = pd.Series(np.random.randn(sLength))\n",
    "# processed_product_descriptions_df = processed_product_descriptions_df.assign(e=e.values)\n",
    "# print(processed_product_descriptions_df.head())\n",
    "# print('-----------------------------------------')\n",
    "# total_sim=0\n",
    "# word_count=0\n",
    "# for index,rr in processed_product_descriptions_df.iterrows():\n",
    "#     #print(lin)\n",
    "#     lin = rr[\"product_description\"]\n",
    "#     query=rr[\"\"]\n",
    "#     query=rr[]\n",
    "    \n",
    "#     for word1 in lin:\n",
    "#         w1 = wordnet.synsets(word1)\n",
    "#         for word2 in qa:\n",
    "#             w2 = wordnet.synsets(word2)\n",
    "#             if w1 and w2:\n",
    "#                 sim = w1[0].wup_similarity(w2[0])\n",
    "#                 #print(sim)\n",
    "#                 if sim!=None and sim > .1:\n",
    "#                     total_sim=total_sim+sim\n",
    "#                     word_count=word_count+1\n",
    "#     if word_count==0:\n",
    "#          rr['e']=None\n",
    "#     else:\n",
    "#         rr['e'] = total_sim/word_count\n",
    "#     print(rr['e'])\n",
    "        \n",
    "        \n",
    "                \n",
    "#     c=c+1\n",
    "#     if c> 4:\n",
    "#         break\n",
    "# print(c)\n",
    "    #if c> 4:\n",
    "        #break\n",
    "# query = \"shower head\"\n",
    "# from lsa.search.machine import SearchMachine\n",
    "# sm = SearchMachine(latent_dimensions=150, index_backend='lsa.keeper.backends.JsonIndexBackend',\n",
    "#                    keep_index_info={'path_to_index_folder': 'index'},\n",
    "#                    db_backend='lsa.db.mysql.MySQLBackend',\n",
    "#                    db_credentials={'db_name': 'news', 'user': 'root', 'password': 'one2012gtr'},\n",
    "#                    tables_info={\n",
    "#                        'news_news': {'fields': ('title', 'text'), 'pk_field_name': 'id', 'prefix': '', 'where': 'id < 300'}\n",
    "#                    },\n",
    "#                    decimals=3,\n",
    "#                    use_tf_idf=False\n",
    "#                    )\n",
    "\n",
    "# sm.build_index()\n",
    "# res = sm.search('natural language query', with_distances=True, limit=10)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>[not, only, do, angle, make, joint, stronger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>[behr, premium, textured, deckover, is, an, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>[classic, architecture, meet, contemporary, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>[the, grape, solar, 265, watt, polycrystalline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>[update, your, bathroom, with, the, delta, ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                product_description\n",
       "0       100001  [not, only, do, angle, make, joint, stronger, ...\n",
       "1       100002  [behr, premium, textured, deckover, is, an, in...\n",
       "2       100003  [classic, architecture, meet, contemporary, de...\n",
       "3       100004  [the, grape, solar, 265, watt, polycrystalline...\n",
       "4       100005  [update, your, bathroom, with, the, delta, ver..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_product_descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(processed_train_df,processed_product_descriptions_df, on='product_uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strong, tie, 12, gauge, angle]</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[not, only, do, angle, make, joint, stronger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strong, tie, 12, gauge, angle]</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>[not, only, do, angle, make, joint, stronger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>[behr, premium, textured, deckover, 1, gal, sc...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[behr, premium, textured, deckover, is, an, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1, handle, shower, only, faucet,...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>[update, your, bathroom, with, the, delta, ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1, handle, shower, only, faucet,...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>[update, your, bathroom, with, the, delta, ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
       "1   3       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
       "2   9       100002  [behr, premium, textured, deckover, 1, gal, sc...   \n",
       "3  16       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
       "4  17       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
       "\n",
       "          search_term  relevance  \\\n",
       "0       angle bracket       3.00   \n",
       "1           l bracket       2.50   \n",
       "2           deck over       3.00   \n",
       "3    rain shower head       2.33   \n",
       "4  shower only faucet       2.67   \n",
       "\n",
       "                                 product_description  \n",
       "0  [not, only, do, angle, make, joint, stronger, ...  \n",
       "1  [not, only, do, angle, make, joint, stronger, ...  \n",
       "2  [behr, premium, textured, deckover, is, an, in...  \n",
       "3  [update, your, bathroom, with, the, delta, ver...  \n",
       "4  [update, your, bathroom, with, the, delta, ver...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [not, only, do, angle, make, joint, stronger, ...\n",
      "1    [not, only, do, angle, make, joint, stronger, ...\n",
      "2    [behr, premium, textured, deckover, is, an, in...\n",
      "3    [update, your, bathroom, with, the, delta, ver...\n",
      "4    [update, your, bathroom, with, the, delta, ver...\n",
      "Name: product_description, dtype: object\n",
      "0.875\n",
      "74067\n",
      "   id  product_uid                                      product_title  \\\n",
      "0   2       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "1   3       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "2   9       100002  [behr, premium, textured, deckover, 1, gal, sc...   \n",
      "3  16       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "4  17       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "\n",
      "          search_term  relevance  \\\n",
      "0       angle bracket       3.00   \n",
      "1           l bracket       2.50   \n",
      "2           deck over       3.00   \n",
      "3    rain shower head       2.33   \n",
      "4  shower only faucet       2.67   \n",
      "\n",
      "                                 product_description         e        e2  \\\n",
      "0  [not, only, do, angle, make, joint, stronger, ... -0.332594  0.585900   \n",
      "1  [not, only, do, angle, make, joint, stronger, ...  0.083204 -1.310326   \n",
      "2  [behr, premium, textured, deckover, is, an, in... -0.331414  0.465870   \n",
      "3  [update, your, bathroom, with, the, delta, ver...  0.515463  0.452570   \n",
      "4  [update, your, bathroom, with, the, delta, ver... -0.893390 -1.495607   \n",
      "\n",
      "         e3        e4  \n",
      "0  1.348283  0.613782  \n",
      "1 -0.913245  0.093863  \n",
      "2 -0.561775 -0.003630  \n",
      "3  0.686265  1.522826  \n",
      "4  0.549984  0.113677  \n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.701032301032301\t100.0\t27160.0\t3.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0\t0.6838842975206613\t0\t0\t2.5\n",
      "-----------------------------------------\n",
      "3\n",
      "0.625\t0.6840867620885119\t0\t34800.0\t3.0\n",
      "-----------------------------------------\n",
      "1\n",
      "0.7072091994692614\t0.6681900830507641\t100.0\t33000.0\t2.33\n",
      "-----------------------------------------\n",
      "3\n",
      "0.7486952675807164\t0.683797729618163\t100.0\t33000.0\t2.67\n",
      "-----------------------------------------\n",
      "9\n",
      "1.0\t0.8857808857808859\t100.0\t91022.22222222222\t3.0\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.7296000417710946\t100.0\t153600.0\t2.67\n",
      "-----------------------------------------\n",
      "4\n",
      "1.0\t0.8499791144527986\t95.0\t48640.0\t3.0\n",
      "-----------------------------------------\n",
      "4\n",
      "1.0\t0.8276847421584264\t100.0\t27000.0\t2.67\n",
      "-----------------------------------------\n",
      "1\n",
      "0\t0\t100.0\t17400.0\t3.0\n",
      "-----------------------------------------\n",
      "10\n",
      "1.0\t0.8933333333333333\t100.0\t23935.8\t2.67\n",
      "-----------------------------------------\n",
      "19\n",
      "0.8666666666666667\t0.6673273597938204\t100.0\t122694.73684210527\t3.0\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.6861111111111111\t94.5\t45053.333333333336\t3.0\n",
      "-----------------------------------------\n",
      "5\n",
      "0.8\t0.6600968652568242\t100.0\t49600.0\t2.0\n",
      "-----------------------------------------\n",
      "18\n",
      "0.8868686868686868\t0.748723373543684\t100.0\t226200.0\t2.67\n",
      "-----------------------------------------\n",
      "2\n",
      "0\t0\t94.0\t8178.0\t2.67\n",
      "-----------------------------------------\n",
      "15\n",
      "0.7801558123249299\t0.8537796697626421\t100.0\t27200.0\t3.0\n",
      "-----------------------------------------\n",
      "1\n",
      "0.6470588235294118\t0.645375694137304\t0\t17000.0\t1.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0.7435941043083901\t0.6658877586122167\t0\t0\t1.67\n",
      "-----------------------------------------\n",
      "0\n",
      "0.6514423076923077\t0.6221937867964699\t0\t0\t2.33\n",
      "-----------------------------------------\n",
      "2\n",
      "0.7142857142857143\t0.6870525988173047\t0\t15640.0\t2.33\n",
      "-----------------------------------------\n",
      "2\n",
      "0.6125816993464053\t0.6487917096663226\t0\t38800.0\t1.33\n",
      "-----------------------------------------\n",
      "2\n",
      "0.7509803921568627\t0.6864465084279324\t100.0\t29100.0\t2.67\n",
      "-----------------------------------------\n",
      "2\n",
      "0.7509803921568627\t0.6864465084279324\t100.0\t19400.0\t2.33\n",
      "-----------------------------------------\n",
      "0\n",
      "0\t0\t0\t0\t1.33\n",
      "-----------------------------------------\n",
      "6\n",
      "0.6469527577112716\t0.6466846510841952\t100.0\t29100.0\t2.33\n",
      "-----------------------------------------\n",
      "4\n",
      "0.709313725490196\t0.6645166838665291\t100.0\t29100.0\t2.33\n",
      "-----------------------------------------\n",
      "5\n",
      "0\t0.7474872564655844\t0\t35372.0\t2.0\n",
      "-----------------------------------------\n",
      "2\n",
      "0\t0.6630890952872377\t0\t37000.0\t2.33\n",
      "-----------------------------------------\n",
      "0\n",
      "0.7264705882352941\t0.6501284182140976\t0\t0\t2.67\n",
      "-----------------------------------------\n",
      "15\n",
      "0.8017740429505135\t0.6983111715612728\t100.0\t168033.33333333334\t2.0\n",
      "-----------------------------------------\n",
      "13\n",
      "0.6698412698412698\t0.674243639664328\t100.0\t177500.0\t2.33\n",
      "-----------------------------------------\n",
      "0\n",
      "0.8571428571428572\t0.7079282430675623\t0\t0\t3.0\n",
      "-----------------------------------------\n",
      "7\n",
      "1.0\t0.7727109593837533\t100.0\t28800.0\t2.0\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t1.0\t91.0\t27936.0\t2.0\n",
      "-----------------------------------------\n",
      "1\n",
      "0.7417582417582418\t0.6879171754171755\t95.5\t37500.0\t2.0\n",
      "-----------------------------------------\n",
      "5\n",
      "0.7395833333333333\t0.6986772486772486\t100.0\t36450.0\t2.33\n",
      "-----------------------------------------\n",
      "2\n",
      "0\t0.8888888888888888\t0\t16600.0\t2.33\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.6955459546959075\t90.0\t64586.66666666667\t2.0\n",
      "-----------------------------------------\n",
      "4\n",
      "0.6875\t0.7236553275156218\t0\t51900.0\t2.67\n",
      "-----------------------------------------\n",
      "0\n",
      "0\t0.6736842105263159\t0\t0\t1.67\n",
      "-----------------------------------------\n",
      "4\n",
      "0.625\t0.7374868499435974\t0\t49564.5\t2.33\n",
      "-----------------------------------------\n",
      "4\n",
      "0.625\t0.7374868499435974\t0\t33043.0\t1.67\n",
      "-----------------------------------------\n",
      "6\n",
      "0.6904761904761905\t0.698119000133881\t91.0\t31040.0\t3.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0.7773809523809524\t0.6928571428571428\t100.0\t0\t1.67\n",
      "-----------------------------------------\n",
      "8\n",
      "1.0\t0.8259803921568627\t100.0\t16600.0\t3.0\n",
      "-----------------------------------------\n",
      "2\n",
      "0.7083333333333333\t0.6259259259259259\t100.0\t16600.0\t1.67\n",
      "-----------------------------------------\n",
      "3\n",
      "0.6831730769230768\t0.6910256410256409\t100.0\t48300.0\t3.0\n",
      "-----------------------------------------\n",
      "5\n",
      "1.0\t0.664435598800924\t100.0\t48300.0\t3.0\n",
      "-----------------------------------------\n",
      "4\n",
      "0.7192982456140351\t0.6570149890099585\t86.0\t57638.00000000001\t1.0\n",
      "-----------------------------------------\n",
      "8\n",
      "0.7192982456140351\t0.65794899495605\t100.0\t62790.00000000001\t3.0\n",
      "-----------------------------------------\n",
      "1\n",
      "0.5263157894736842\t0.6267213683719105\t0\t32200.000000000004\t2.67\n",
      "-----------------------------------------\n",
      "3\n",
      "0.5358851674641147\t0.6500525021422856\t0\t45563.0\t2.67\n",
      "-----------------------------------------\n",
      "0\n",
      "0.8242637844611529\t0.6843368298941056\t0\t0\t3.0\n",
      "-----------------------------------------\n",
      "4\n",
      "0.7666666666666666\t0.8909090909090908\t100.0\t32200.000000000004\t2.67\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.7515881206283681\t0\t30375.333333333332\t3.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0.5964912280701754\t0.6060538250387875\t0\t0\t1.0\n",
      "-----------------------------------------\n",
      "5\n",
      "0.8444444444444444\t0.8666666666666666\t100.0\t31200.000000000004\t2.33\n",
      "-----------------------------------------\n",
      "13\n",
      "0.8305555555555555\t0.7754033071183708\t95.5\t80128.0\t2.33\n",
      "-----------------------------------------\n",
      "5\n",
      "0.8444444444444444\t0.6997739050345662\t100.0\t41600.0\t3.0\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.7444158036021427\t100.0\t20800.0\t2.33\n",
      "-----------------------------------------\n",
      "4\n",
      "0.8030228758169935\t0.7326718321737301\t100.0\t19380.0\t2.5\n",
      "-----------------------------------------\n",
      "5\n",
      "0.9705882352941176\t0.7065941436262294\t100.0\t89838.0\t2.33\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.6876623376623375\t100.0\t37200.0\t3.0\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.8105263157894737\t100.0\t31200.0\t2.33\n",
      "-----------------------------------------\n",
      "4\n",
      "1.0\t0.614100185528757\t100.0\t44459.99999999999\t2.33\n",
      "-----------------------------------------\n",
      "10\n",
      "1.0\t0.7271671826625387\t100.0\t45864.0\t2.33\n",
      "-----------------------------------------\n",
      "5\n",
      "1.0\t0.7604588394062077\t100.0\t46800.0\t3.0\n",
      "-----------------------------------------\n",
      "3\n",
      "0.8592592592592593\t0.6456239280155688\t89.75\t65169.99999999999\t3.0\n",
      "-----------------------------------------\n",
      "9\n",
      "0.7512820512820512\t0.7361622807017547\t100.0\t73500.0\t2.33\n",
      "-----------------------------------------\n",
      "2\n",
      "0\t0\t100.0\t13700.0\t2.33\n",
      "-----------------------------------------\n",
      "6\n",
      "0.7666666666666666\t0.7083333333333333\t90.0\t25500.0\t2.0\n",
      "-----------------------------------------\n",
      "12\n",
      "0.7666666666666666\t0.7445454545454544\t89.0\t40851.0\t2.0\n",
      "-----------------------------------------\n",
      "4\n",
      "1.0\t0.6515134336562907\t100.0\t58599.0\t2.33\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "1.0\t0.8446280991735537\t100.0\t15300.000000000002\t2.67\n",
      "-----------------------------------------\n",
      "5\n",
      "0.7276190476190475\t0.6925174853661897\t100.0\t73440.0\t1.67\n",
      "-----------------------------------------\n",
      "6\n",
      "0.7328947368421052\t0.7369140989729225\t96.66666666666667\t26100.0\t3.0\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.801923076923077\t100.0\t10800.0\t2.33\n",
      "-----------------------------------------\n",
      "3\n",
      "1.0\t0.801923076923077\t100.0\t10800.0\t3.0\n",
      "-----------------------------------------\n",
      "9\n",
      "0.8266666666666665\t0.7238020047762697\t100.0\t37500.0\t2.0\n",
      "-----------------------------------------\n",
      "4\n",
      "1.0\t1.0\t100.0\t37800.0\t2.67\n",
      "-----------------------------------------\n",
      "2\n",
      "0.6879256965944271\t0.6630602602238005\t93.0\t24738.0\t3.0\n",
      "-----------------------------------------\n",
      "5\n",
      "1.0\t0.9065934065934066\t100.0\t39900.0\t3.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0\t0\t0\t0\t2.33\n",
      "-----------------------------------------\n",
      "1\n",
      "0\t0\t86.0\t5676.0\t3.0\n",
      "-----------------------------------------\n",
      "9\n",
      "0.8970588235294118\t0.7136685814676749\t92.66666666666667\t46814.0\t3.0\n",
      "-----------------------------------------\n",
      "11\n",
      "0.8970588235294118\t0.7447303807812925\t100.0\t78900.0\t3.0\n",
      "-----------------------------------------\n",
      "14\n",
      "0.8970588235294118\t0.7402935924405842\t92.66666666666667\t48880.42857142857\t2.67\n",
      "-----------------------------------------\n",
      "3\n",
      "0.804953560371517\t0.672300074230985\t100.0\t58800.00000000001\t2.33\n",
      "-----------------------------------------\n",
      "3\n",
      "0.7084807607253428\t0.6454150900126131\t100.0\t44100.0\t3.0\n",
      "-----------------------------------------\n",
      "3\n",
      "0.804953560371517\t0.672300074230985\t100.0\t58800.00000000001\t2.0\n",
      "-----------------------------------------\n",
      "3\n",
      "0.7639628482972136\t0.7542391518010714\t100.0\t29400.000000000004\t2.67\n",
      "-----------------------------------------\n",
      "3\n",
      "0.772578505086245\t0.7129934978377317\t100.0\t44100.0\t2.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0\t0.6332190957190957\t0\t0\t1.33\n",
      "-----------------------------------------\n",
      "19\n",
      "0.7895833333333333\t0.803659359468089\t100.0\t78468.84210526316\t2.33\n",
      "-----------------------------------------\n",
      "17\n",
      "1.0\t0.8288669579237533\t100.0\t39565.88235294118\t2.33\n",
      "-----------------------------------------\n",
      "8\n",
      "0.8\t0.714900888585099\t94.5\t56416.5\t2.0\n",
      "-----------------------------------------\n",
      "1\n",
      "0.76875\t0.6828947368421054\t100.0\t39800.0\t1.33\n",
      "-----------------------------------------\n",
      "14\n",
      "1.0\t0.9725274725274725\t90.0\t39515.71428571428\t3.0\n",
      "-----------------------------------------\n",
      "0\n",
      "0.8888888888888888\t0.6783625730994152\t96.5\t0\t3.0\n",
      "-----------------------------------------\n",
      "4\n",
      "0.808187134502924\t0.6599049707602339\t100.0\t44497.5\t2.33\n",
      "-----------------------------------------\n",
      "1\n",
      "1.0\t0.7166666666666666\t100.0\t17000.0\t3.0\n",
      "-----------------------------------------\n",
      "2\n",
      "0.8295454545454546\t0.7379878618113911\t86.0\t13578.0\t2.67\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t1.0\t100.0\t23400.0\t2.33\n",
      "-----------------------------------------\n",
      "7\n",
      "1.0\t1.0\t100.0\t23400.0\t3.0\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t1.0\t100.0\t11700.0\t2.33\n",
      "-----------------------------------------\n",
      "1\n",
      "0.7666666666666666\t0.6940559440559441\t100.0\t13000.0\t2.0\n",
      "-----------------------------------------\n",
      "2\n",
      "0.739766081871345\t0.6896407685881369\t100.0\t13000.0\t2.67\n",
      "-----------------------------------------\n",
      "1\n",
      "0.6461988304093567\t0.6516290726817042\t0\t17745.0\t2.67\n",
      "-----------------------------------------\n",
      "0\n",
      "0.625\t0.6224211724163351\t0\t0\t2.67\n",
      "-----------------------------------------\n",
      "9\n",
      "0.7097222222222221\t0.6668722459744133\t100.0\t70400.0\t2.33\n",
      "-----------------------------------------\n",
      "0\n",
      "0.6332323232323231\t0.6413135927728545\t0\t0\t1.33\n",
      "-----------------------------------------\n",
      "9\n",
      "1.0\t1.0\t89.66666666666667\t36672.0\t2.0\n",
      "-----------------------------------------\n",
      "10\n",
      "1.0\t0.9814814814814814\t98.0\t55987.2\t2.33\n",
      "-----------------------------------------\n",
      "14\n",
      "0.9242424242424242\t0.7446180396719696\t100.0\t97920.0\t2.0\n",
      "-----------------------------------------\n",
      "11\n",
      "0.7679425837320574\t0.6433941895737562\t94.33333333333333\t64014.545454545456\t2.67\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.7056084395480681\t100.0\t28800.0\t2.67\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.7029276622929874\t92.0\t26496.0\t2.33\n",
      "-----------------------------------------\n",
      "10\n",
      "0.8529411764705883\t0.7528549881491059\t95.5\t39139.200000000004\t2.33\n",
      "-----------------------------------------\n",
      "6\n",
      "1.0\t0.6729902267924714\t100.0\t57600.0\t1.33\n",
      "-----------------------------------------\n",
      "9\n",
      "0.7777777777777778\t0.6710980883581504\t100.0\t28160.0\t2.33\n",
      "-----------------------------------------\n",
      "11\n",
      "0.8518518518518517\t0.6994793458319001\t100.0\t43200.0\t2.67\n",
      "-----------------------------------------\n",
      "9\n",
      "0.8863636363636364\t0.7140955999624731\t100.0\t42240.0\t3.0\n",
      "-----------------------------------------\n",
      "22\n",
      "0.8398148148148148\t0.7384135290271713\t100.0\t155500.0\t2.33\n",
      "-----------------------------------------\n",
      "23\n",
      "1.0\t0.7860389169518226\t90.66666666666667\t81698.34782608696\t2.0\n",
      "-----------------------------------------\n",
      "11\n",
      "1.0\t0.7860389169518226\t100.0\t62200.0\t1.67\n",
      "-----------------------------------------\n",
      "20\n",
      "0.95\t0.7974160787309575\t100.0\t124400.00000000001\t2.67\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3389acfcfbcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwup_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;31m#print(sim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mwup_similarity\u001b[0;34m(self, other, verbose, simulate_root)\u001b[0m\n\u001b[1;32m    899\u001b[0m         subsumers = self.lowest_common_hypernyms(\n\u001b[1;32m    900\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m             \u001b[0msimulate_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimulate_root\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mneed_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_min_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m         )\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlowest_common_hypernyms\u001b[0;34m(self, other, simulate_root, use_min_depth)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 unsorted_lch = [\n\u001b[0;32m--> 642\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m                 ]\n\u001b[1;32m    644\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 unsorted_lch = [\n\u001b[0;32m--> 642\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m                 ]\n\u001b[1;32m    644\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mmin_depth\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_min_depth\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mhypernyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_hypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhypernyms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mhypernyms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_related\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_hypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_related\u001b[0;34m(self, relation_symbol, sort)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mget_synset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wordnet_corpus_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset_from_pos_and_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mpointer_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pointers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelation_symbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpointer_tuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mget_synset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wordnet_corpus_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset_from_pos_and_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mpointer_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pointers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelation_symbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpointer_tuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(df_merge[\"product_description\"].head(5) )\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "query = 'shower head'\n",
    "qa= query.split(\" \")\n",
    "c=0\n",
    "w1 = wordnet.synsets(\"dog\")[0]\n",
    "w2 = wordnet.synsets(\"animal\")[0]\n",
    "print(w1.wup_similarity(w2))\n",
    "sLength = len(df_merge[\"product_description\"])\n",
    "print(sLength)\n",
    "e = pd.Series(np.random.randn(sLength))\n",
    "df_merge = df_merge.assign(e=e.values)\n",
    "e2 = pd.Series(np.random.randn(sLength))\n",
    "df_merge = df_merge.assign(e2=e2.values)\n",
    "e3 = pd.Series(np.random.randn(sLength))\n",
    "df_merge = df_merge.assign(e3=e3.values)\n",
    "e4 = pd.Series(np.random.randn(sLength))\n",
    "df_merge = df_merge.assign(e4=e4.values)\n",
    "print(df_merge.head())\n",
    "print('-----------------------------------------')\n",
    "total_sim=0\n",
    "word_count=0\n",
    "from fuzzywuzzy import fuzz\n",
    "for index,rr in df_merge.iterrows():\n",
    "    print('-----------------------------------------')\n",
    "    rr['e']=None\n",
    "    rr['e2']=None\n",
    "    rr['e3']=None\n",
    "    rr['e4']=None\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(lin)\n",
    "    total_sim=0\n",
    "    total_sim2=0\n",
    "    word_count=0\n",
    "    word_count2=0\n",
    "    threshold2=78\n",
    "    lin = rr[\"product_title\"]\n",
    "    query=rr[\"search_term\"]\n",
    "    qa= query.split(\" \")\n",
    "    lin2= rr[\"product_description\"]\n",
    "    for word1 in lin:\n",
    "        w1 = wordnet.synsets(word1)\n",
    "        for word2 in qa:\n",
    "            sim2=fuzz.ratio(word1, word2)\n",
    "            if sim2!=None and sim2 > threshold2:\n",
    "                    total_sim2=total_sim2+sim2\n",
    "                    word_count2=word_count2+1\n",
    "            \n",
    "            w2 = wordnet.synsets(word2)\n",
    "            \n",
    "            if w1 and w2:\n",
    "                sim = w1[0].wup_similarity(w2[0])\n",
    "                #print(sim)\n",
    "                if sim!=None and sim > .5:\n",
    "                    total_sim=total_sim+sim\n",
    "                    word_count=word_count+1\n",
    "    #word_count2=len(qa)\n",
    "    if word_count==0:\n",
    "         rr['e']=0\n",
    "    else:\n",
    "        rr['e'] = total_sim/word_count\n",
    "    #print(rr['e'])\n",
    "    if word_count2==0:\n",
    "         rr['e3']=0\n",
    "    else:\n",
    "        #rr['e3'] = total_sim2/word_count2\n",
    "        rr['e3'] = total_sim2/(word_count2)\n",
    "    #print(rr['e3'])\n",
    "    #print( str(rr['e'])+'\\t'+str(rr['e2'])+'\\t'+str(rr['e3'])+'\\t'+str(rr['e4']) )\n",
    "    total_sim=0\n",
    "    total_sim2=0\n",
    "    word_count=0\n",
    "    word_count=0\n",
    "    word_count2=0\n",
    "    for word1 in lin2:\n",
    "        w1 = wordnet.synsets(word1)\n",
    "        for word2 in qa:\n",
    "            sim2=fuzz.ratio(word1, word2)\n",
    "            if sim2!=None and sim2 > threshold2:\n",
    "                    total_sim2=total_sim2+sim2\n",
    "                    word_count2=word_count2+1\n",
    "            \n",
    "            w2 = wordnet.synsets(word2)\n",
    "            if w1 and w2:\n",
    "                sim = w1[0].wup_similarity(w2[0])\n",
    "                #print(sim)\n",
    "                if sim!=None and sim > .5:\n",
    "                    total_sim=total_sim+sim\n",
    "                    word_count=word_count+1\n",
    "    #word_count2=len(qa)\n",
    "    print(word_count2)\n",
    "    factor2= word_count2/(len(qa)*len(lin2) )\n",
    "    if word_count==0:\n",
    "         rr['e2']=0\n",
    "    else:\n",
    "        rr['e2'] = total_sim/word_count\n",
    "        \n",
    "    if word_count2==0:\n",
    "         rr['e4']=0\n",
    "    else:\n",
    "#         print('----')\n",
    "        \n",
    "#         print(total_sim2)\n",
    "#         print(word_count2)\n",
    "#         print('----')\n",
    "        \n",
    "        rr['e4'] = total_sim2/(factor2)\n",
    "   # print(rr['e2'])\n",
    "    \n",
    "#     delimiter = ' '\n",
    "#     s1 = delimiter.join(lind\n",
    "#     s2 = delimiter.join(lin2)ddd\n",
    "#     r1=fuzz.ratio(query, s1)\n",
    "#     rr['e3']=r1\n",
    "#     r1=fuzz.ratio(query, s2)\n",
    "    #rr['e4']=None\n",
    "    print( str(rr['e'])+'\\t'+str(rr['e2'])+'\\t'+str(rr['e3'])+'\\t'+str(rr['e4']) +'\\t'+str(rr['relevance'])) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "r1=fuzz.ratio(\"this is a test\", \"this is a test!\")\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
