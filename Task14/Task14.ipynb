{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv files to data frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('data/train.csv',encoding = \"latin1\")\n",
    "#test_df = pd.read_csv('data/test.csv',encoding = \"latin1\")\n",
    "#attributes_df = pd.read_csv('data/attributes.csv',encoding = \"latin1\")\n",
    "#product_descriptions_df = pd.read_csv('data/product_descriptions.csv',encoding = \"latin1\")\n",
    "#sample_submission_df = pd.read_csv('data/sample_submission.csv', encoding = \"latin1\")\n",
    "from pyspark.sql import SparkSession\n",
    "spark  = SparkSession.builder.appName(\"task14\").getOrCreate()\n",
    "train_df = spark.read.option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"data/train.csv\")\n",
    "product_descriptions_df = spark.read.option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"data/product_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = train_df.join(product_descriptions_df,'product_uid')\n",
    "merged_rdd = merged_df.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('100001', '3', 'Simpson Strong-Tie 12-Gauge Angle', 'l bracket', '2.5', '\"Not only do angles make joints stronger, they also provide more consistent, straight corners. Simpson Strong-Tie offers a wide variety of angles in various sizes and thicknesses to handle light-duty jobs or projects where a structural connection is needed. Some can be bent (skewed) to match the project. For outdoor projects or those where moisture is present, use our ZMAX zinc-coated connectors, which provide extra resistance against corrosion (look for a \"\"Z\"\" at the end of the model number).Versatile connector for various 90 connections and home repair projectsStronger than angled nailing or screw fastening aloneHelp ensure joints are consistently straight and strongDimensions: 3 in. x 3 in. x 1-1/2 in.Made from 12-Gauge steelGalvanized for extra corrosion resistanceInstall with 10d common nails or #9 x 1-1/2 in. Strong-Drive SD screws\"')\n"
     ]
    }
   ],
   "source": [
    "print(merged_rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 int64\n",
      "product_uid        int64\n",
      "product_title     object\n",
      "search_term       object\n",
      "relevance        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_uid             int64\n",
      "product_description    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(product_descriptions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_uid                                product_description\n",
      "0       100001  Not only do angles make joints stronger, they ...\n",
      "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
      "2       100003  Classic architecture meets contemporary design...\n",
      "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
      "4       100005  Update your bathroom with the Delta Vero Singl...\n"
     ]
    }
   ],
   "source": [
    "#print(product_descriptions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NLTK's stopwords list and WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and tokenize the raw text by:\n",
    "    1. Convert to lower case\n",
    "    2. Remove apostrophe\n",
    "    3. Remove Punctuation\n",
    "    4. Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "   \n",
    "    # convert text to lower case\n",
    "    lowercase = str(text).lower()\n",
    "    \n",
    "    #remove 's from string\n",
    "    apoRemoved = lowercase.replace(\"'s\",\"\")\n",
    "    \n",
    "    #convert don't to dont\n",
    "    apoRemoved = apoRemoved.replace(\"'\",\"\")\n",
    "    \n",
    "    #handle other punctuations\n",
    "    transtable = str.maketrans(string.punctuation,\"                                \")\n",
    "    brokenWords = apoRemoved.translate(transtable)\n",
    "    \n",
    "    #convert string to list of words\n",
    "    listOfWords =  nltk.word_tokenize(brokenWords)\n",
    "    \n",
    "    #lemmatize text\n",
    "    lemmatizedList=[lemmatizer.lemmatize(word) for word in listOfWords]\n",
    "   \n",
    "    return lemmatizedList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'here', 'dont', 'car']\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "text = \"Dogs Here's don't cars.\"\n",
    "print(process(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process train_df\n",
    "def process_train_df(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \n",
    "    newdf=df\n",
    "    for i,row in newdf.iterrows():\n",
    "#         if i>5:\n",
    "#             break\n",
    "#         print(\"raw: \",text)\n",
    "        newdf.at[i,'product_title'] = process(row['product_title'])\n",
    "#         print(\"processed: \",df.iloc[i]['product_title'])\n",
    "    return newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid                                      product_title  \\\n",
      "0   2       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "1   3       100001           [simpson, strong, tie, 12, gauge, angle]   \n",
      "2   9       100002  [behr, premium, textured, deckover, 1, gal, sc...   \n",
      "3  16       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "4  17       100005  [delta, vero, 1, handle, shower, only, faucet,...   \n",
      "\n",
      "          search_term  relevance  \n",
      "0       angle bracket       3.00  \n",
      "1           l bracket       2.50  \n",
      "2           deck over       3.00  \n",
      "3    rain shower head       2.33  \n",
      "4  shower only faucet       2.67  \n"
     ]
    }
   ],
   "source": [
    "#processed_train_df = process_train_df(train_df)\n",
    "#print(processed_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process \n",
    "def process_product_descriptions_df(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    \n",
    "    newdf=df\n",
    "    for i,row in newdf.iterrows():\n",
    "#         if i>5:\n",
    "#             break\n",
    "#         print(\"raw: \",text)\n",
    "        newdf.at[i,'product_description'] = process(row['product_description'])\n",
    "#         print(\"processed: \",df.iloc[i]['product_title'])\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_uid                                product_description\n",
      "0       100001  [not, only, do, angle, make, joint, stronger, ...\n",
      "1       100002  [behr, premium, textured, deckover, is, an, in...\n",
      "2       100003  [classic, architecture, meet, contemporary, de...\n",
      "3       100004  [the, grape, solar, 265, watt, polycrystalline...\n",
      "4       100005  [update, your, bathroom, with, the, delta, ver...\n"
     ]
    }
   ],
   "source": [
    "#processed_product_descriptions_df = process_product_descriptions_df(product_descriptions_df)\n",
    "#print(processed_product_descriptions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_rdd = merged_rdd.map(lambda row: (row[0], row[1], process(row[2]), process(row[3]), float(row[4]), process(row[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('100001',\n",
       " '3',\n",
       " ['simpson', 'strong', 'tie', '12', 'gauge', 'angle'],\n",
       " ['l', 'bracket'],\n",
       " 2.5,\n",
       " ['not',\n",
       "  'only',\n",
       "  'do',\n",
       "  'angle',\n",
       "  'make',\n",
       "  'joint',\n",
       "  'stronger',\n",
       "  'they',\n",
       "  'also',\n",
       "  'provide',\n",
       "  'more',\n",
       "  'consistent',\n",
       "  'straight',\n",
       "  'corner',\n",
       "  'simpson',\n",
       "  'strong',\n",
       "  'tie',\n",
       "  'offer',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'angle',\n",
       "  'in',\n",
       "  'various',\n",
       "  'size',\n",
       "  'and',\n",
       "  'thickness',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'light',\n",
       "  'duty',\n",
       "  'job',\n",
       "  'or',\n",
       "  'project',\n",
       "  'where',\n",
       "  'a',\n",
       "  'structural',\n",
       "  'connection',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'some',\n",
       "  'can',\n",
       "  'be',\n",
       "  'bent',\n",
       "  'skewed',\n",
       "  'to',\n",
       "  'match',\n",
       "  'the',\n",
       "  'project',\n",
       "  'for',\n",
       "  'outdoor',\n",
       "  'project',\n",
       "  'or',\n",
       "  'those',\n",
       "  'where',\n",
       "  'moisture',\n",
       "  'is',\n",
       "  'present',\n",
       "  'use',\n",
       "  'our',\n",
       "  'zmax',\n",
       "  'zinc',\n",
       "  'coated',\n",
       "  'connector',\n",
       "  'which',\n",
       "  'provide',\n",
       "  'extra',\n",
       "  'resistance',\n",
       "  'against',\n",
       "  'corrosion',\n",
       "  'look',\n",
       "  'for',\n",
       "  'a',\n",
       "  'z',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'model',\n",
       "  'number',\n",
       "  'versatile',\n",
       "  'connector',\n",
       "  'for',\n",
       "  'various',\n",
       "  '90',\n",
       "  'connection',\n",
       "  'and',\n",
       "  'home',\n",
       "  'repair',\n",
       "  'projectsstronger',\n",
       "  'than',\n",
       "  'angled',\n",
       "  'nailing',\n",
       "  'or',\n",
       "  'screw',\n",
       "  'fastening',\n",
       "  'alonehelp',\n",
       "  'ensure',\n",
       "  'joint',\n",
       "  'are',\n",
       "  'consistently',\n",
       "  'straight',\n",
       "  'and',\n",
       "  'strongdimensions',\n",
       "  '3',\n",
       "  'in',\n",
       "  'x',\n",
       "  '3',\n",
       "  'in',\n",
       "  'x',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  'in',\n",
       "  'made',\n",
       "  'from',\n",
       "  '12',\n",
       "  'gauge',\n",
       "  'steelgalvanized',\n",
       "  'for',\n",
       "  'extra',\n",
       "  'corrosion',\n",
       "  'resistanceinstall',\n",
       "  'with',\n",
       "  '10d',\n",
       "  'common',\n",
       "  'nail',\n",
       "  'or',\n",
       "  '9',\n",
       "  'x',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  'in',\n",
       "  'strong',\n",
       "  'drive',\n",
       "  'sd',\n",
       "  'screw'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "def tfidf_sim(row, stopwords=nltk.corpus.stopwords.words('english')):\n",
    "    title = row[2]\n",
    "    search = row[3]\n",
    "    relevance = row[4]\n",
    "    desc = row[5]\n",
    "    title_search = []\n",
    "    title_search.append(title)\n",
    "    title_search.append(search)\n",
    "    desc_search = []\n",
    "    desc_search.append(desc)\n",
    "    desc_search.append(search)\n",
    "    vect = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun,preprocessor=dummy_fun,token_pattern=None,stop_words=stopwords,use_idf=False)\n",
    "    tfidf1 = vect.fit_transform(title_search)\n",
    "    tfidf2 = vect.fit_transform(desc_search)\n",
    "    title_sim_value = (tfidf1 * tfidf1.T).A[0,1]\n",
    "    desc_sim_value = (tfidf2 * tfidf2.T).A[0,1]\n",
    "    return (row[0],row[1],row[2], row[3], float(title_sim_value), float(desc_sim_value), relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdd = processed_rdd.map(tfidf_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100001',\n",
       "  '3',\n",
       "  ['simpson', 'strong', 'tie', '12', 'gauge', 'angle'],\n",
       "  ['l', 'bracket'],\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5),\n",
       " ('100001',\n",
       "  '2',\n",
       "  ['simpson', 'strong', 'tie', '12', 'gauge', 'angle'],\n",
       "  ['angle', 'bracket'],\n",
       "  0.2886751345948129,\n",
       "  0.11826247919781652,\n",
       "  3.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_rdd.toDF([\"product_id\",\"id\",\"product_title\",\"search_term\",\"title_sim\",\"desc_sim\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+--------------------+--------------------+-------------------+-------------------+-----+\n",
      "|product_id| id|       product_title|         search_term|          title_sim|           desc_sim|label|\n",
      "+----------+---+--------------------+--------------------+-------------------+-------------------+-----+\n",
      "|    100001|  3|[simpson, strong,...|        [l, bracket]|                0.0|                0.0|  2.5|\n",
      "|    100001|  2|[simpson, strong,...|    [angle, bracket]| 0.2886751345948129|0.11826247919781652|  3.0|\n",
      "|    100002|  9|[behr, premium, t...|        [deck, over]|                0.0|0.22808577638091165|  3.0|\n",
      "|    100005| 17|[delta, vero, 1, ...|[shower, only, fa...|0.42640143271122083|0.15339299776947407| 2.67|\n",
      "|    100005| 16|[delta, vero, 1, ...|[rain, shower, head]|0.17407765595569785|0.06262242910851495| 2.33|\n",
      "|    100006| 21|[whirlpool, 1, 9,...|         [microwave]| 0.2886751345948129|0.13784910335911552|  3.0|\n",
      "|    100006| 20|[whirlpool, 1, 9,...|[microwave, over,...| 0.2041241452319315|0.09747403576571587| 2.67|\n",
      "|    100006| 18|[whirlpool, 1, 9,...|   [convection, otr]| 0.2041241452319315|0.09747403576571587|  3.0|\n",
      "|    100007| 23|[lithonia, lighti...|  [emergency, light]| 0.4472135954999579|0.24077170617153837| 2.67|\n",
      "|    100009| 27|[house, of, fara,...|         [mdf, 3, 4]| 0.5773502691896258|0.27407548393101266|  3.0|\n",
      "|    100010| 34|[valley, view, in...|     [steele, stake]|0.26726124191242434|0.36293309315564887| 2.67|\n",
      "|    100012| 48|[hampton, bay, ca...|[hampton, bay, ch...| 0.3721042037676254| 0.1900028500641266| 2.67|\n",
      "|    100013| 51|[insinkerator, si...|          [disposer]|                0.0|                0.0| 2.67|\n",
      "|    100016| 65|[sunjoy, calais, ...|     [grill, gazebo]|  0.282842712474619| 0.7009039702739965|  3.0|\n",
      "|    100017| 85|[md, building, pr...|    [window, screen]|                0.0|0.14213381090374028| 2.33|\n",
      "|    100017| 81|[md, building, pr...|   [radiator, grate]|                0.0|                0.0| 2.33|\n",
      "|    100017| 75|[md, building, pr...|[metal, plate, co...|                0.0|                0.0| 1.67|\n",
      "|    100017| 69|[md, building, pr...|       [door, guard]|                0.0|0.07106690545187014|  1.0|\n",
      "|    100019|106|[house, of, fara,...|[wainscot, plank,...| 0.3481553119113957| 0.2057377999494559| 2.33|\n",
      "|    100019|105|[house, of, fara,...|[wainscot, chair,...|0.17407765595569785| 0.3086066999241839| 2.33|\n",
      "+----------+---+--------------------+--------------------+-------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"title_sim\",\"desc_sim\"],outputCol=\"features\")\n",
    "final_df = assembler.transform(new_df).drop('product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|features                                 |\n",
      "+-----------------------------------------+\n",
      "|(2,[],[])                                |\n",
      "|[0.2886751345948129,0.11826247919781652] |\n",
      "|[0.0,0.22808577638091165]                |\n",
      "|[0.42640143271122083,0.15339299776947407]|\n",
      "|[0.17407765595569785,0.06262242910851495]|\n",
      "|[0.2886751345948129,0.13784910335911552] |\n",
      "|[0.2041241452319315,0.09747403576571587] |\n",
      "|[0.2041241452319315,0.09747403576571587] |\n",
      "|[0.4472135954999579,0.24077170617153837] |\n",
      "|[0.5773502691896258,0.27407548393101266] |\n",
      "|[0.26726124191242434,0.36293309315564887]|\n",
      "|[0.3721042037676254,0.1900028500641266]  |\n",
      "|(2,[],[])                                |\n",
      "|[0.282842712474619,0.7009039702739965]   |\n",
      "|[0.0,0.14213381090374028]                |\n",
      "|(2,[],[])                                |\n",
      "|(2,[],[])                                |\n",
      "|[0.0,0.07106690545187014]                |\n",
      "|[0.3481553119113957,0.2057377999494559]  |\n",
      "|[0.17407765595569785,0.3086066999241839] |\n",
      "+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=5, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0]\n",
      "Intercept: 2.381798094242814\n",
      "numIterations: 1\n",
      "objectiveHistory: [0.4999999999999982]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| 0.11820190575718614|\n",
      "|  0.6182019057571861|\n",
      "|  0.6182019057571861|\n",
      "| 0.28820190575718607|\n",
      "|-0.05179809424281...|\n",
      "|  0.6182019057571861|\n",
      "| 0.28820190575718607|\n",
      "|  0.6182019057571861|\n",
      "| 0.28820190575718607|\n",
      "|  0.6182019057571861|\n",
      "| 0.28820190575718607|\n",
      "| 0.28820190575718607|\n",
      "| 0.28820190575718607|\n",
      "|  0.6182019057571861|\n",
      "|-0.05179809424281...|\n",
      "|-0.05179809424281...|\n",
      "| -0.7117980942428139|\n",
      "| -1.3817980942428139|\n",
      "|-0.05179809424281...|\n",
      "|-0.05179809424281...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 0.534005\n",
      "r2: 0.000000\n"
     ]
    }
   ],
   "source": [
    "lrModel = lr.fit(final_df)\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
